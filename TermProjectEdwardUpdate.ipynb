{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataPath = '/s/bach/g/under/cutreap/Desktop/cs445/cell_images/'\n",
    "dataRoot = pathlib.Path(dataPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageDirs = []\n",
    "for item in dataRoot.iterdir():\n",
    "    imageDirs.append(item)\n",
    "\n",
    "dataRoot = []\n",
    "for path in imageDirs:\n",
    "    dataRoot.append(pathlib.Path(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeledImages = []\n",
    "label = 0\n",
    "classes = sorted(os.walk(dataPath).__next__()[1])\n",
    "# List each sub-directory (the classes)\n",
    "for c in classes:\n",
    "    c_dir = os.path.join(dataPath, c)\n",
    "    walk = os.walk(c_dir).__next__()\n",
    "    # Add each image to the training set\n",
    "    for sample in walk[2]:\n",
    "        # Only keeps jpeg images\n",
    "        if sample.endswith('.png') or sample.endswith('.jpeg'):\n",
    "            labeledImages.append( (label, os.path.join(c_dir, sample)) )\n",
    "    label += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeledTrain = []\n",
    "labeledTest = []\n",
    "i = 0\n",
    "for image in labeledImages:\n",
    "    if(i < .8*len(labeledImages)):\n",
    "        labeledTrain.append(image)\n",
    "        i += 1\n",
    "    else:\n",
    "        labeledTest.append(image)\n",
    "trainPaths = [x[1] for x in labeledTrain]\n",
    "trainLabels = [x[0] for x in labeledTrain]\n",
    "testPaths = [x[1] for x in labeledTest]\n",
    "testLabels = [x[0] for x in labeledTest]\n",
    "testSize = len(testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trainPaths = []\n",
    "#trainLabels = []\n",
    "#testPaths = []\n",
    "#testLabels = []\n",
    "#for i in range(len(imagePaths)):\n",
    "#    if(i < .8*len(imagePaths)):\n",
    "#        trainPaths.append(imagePaths[i])\n",
    "#        trainLabels.append(labels[i])\n",
    "#    else:\n",
    "#        testPaths.append(imagePaths[i])\n",
    "#        testLabels.append(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def loadAndPreprocessImage(path):\n",
    "  image = tf.read_file(path)\n",
    "  image = tf.image.decode_png(image, channels=3)\n",
    "  image = tf.image.resize_images(image, [128, 128])\n",
    "  image = image / 127.5 - 1.0  # normalize to [-1,1] range\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepDataForConvNet(imagePaths, labels, batch_size):\n",
    "    # Convert to Tensor\n",
    "    imagePaths = tf.convert_to_tensor(imagePaths, dtype=tf.string)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    # Build a TF Queue, shuffle data\n",
    "    image, label = tf.train.slice_input_producer([imagePaths, labels],\n",
    "                                                 shuffle=True)\n",
    "\n",
    "    # Read images from disk\n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_png(image, channels=CHANNELS)\n",
    "\n",
    "    # Resize images to a common size\n",
    "    image = tf.image.resize_images(image, [128, 128])\n",
    "    \n",
    "    \n",
    "\n",
    "    # Normalize\n",
    "    image = image * 1.0/127.5 - 1.0\n",
    "\n",
    "    # Create batches\n",
    "    X, Y = tf.train.batch([image, label], batch_size=batch_size,\n",
    "                          capacity=batch_size * 8,\n",
    "                          num_threads=4)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "batchSize = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# Image Parameters_\n",
    "N_CLASSES = 2 # CHANGE HERE, total number of classes\n",
    "IMG_HEIGHT = 128 # CHANGE HERE, the image height to be resized to\n",
    "IMG_WIDTH = 128 # CHANGE HERE, the image width to be resized to\n",
    "CHANNELS = 3 # The 3 color channels, change to 1 if grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-ece6a30fbb0a>:7: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-ece6a30fbb0a>:24: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "trainImages, trainLabels = prepDataForConvNet(trainPaths, trainLabels, batchSize)\n",
    "testImages, testLabels = prepDataForConvNet(testPaths, testLabels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trainPathDS = tf.data.Dataset.from_tensor_slices(trainPaths)\n",
    "#trainImageDS = trainPathDS.map(loadAndPreprocessImage, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#trainLabelDS = tf.data.Dataset.from_tensor_slices(tf.cast(trainLabels, tf.int64))\n",
    "#trainDS = tf.data.Dataset.zip((trainImageDS, trainLabelDS))\n",
    "\n",
    "#testPathDS = tf.data.Dataset.from_tensor_slices(testPaths)\n",
    "#testImageDS = testPathDS.map(loadAndPreprocessImage, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#testLabelDS = tf.data.Dataset.from_tensor_slices(tf.cast(testLabels, tf.int64))\n",
    "#testDS = tf.data.Dataset.zip((testImageDS, testLabelDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def conv_net(images, n_classes, dropout, reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(images, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 5, 3)\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2 \n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 5, 3)\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(conv2, 128, 3)\n",
    "        conv3 = tf.layers.max_pooling2d(conv3, 3, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv3)\n",
    "\n",
    "        # Fully connected layer (in contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "        # Because 'softmax_cross_entropy_with_logits' already apply softmax,\n",
    "        # we only apply softmax to testing network\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-298035ad32ec>:7: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-11-298035ad32ec>:9: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-11-298035ad32ec>:23: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-11-298035ad32ec>:25: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-12-f1546c109a4b>:34: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Step 1, Minibatch Loss= 0.6647, Training Accuracy= 0.648\n",
      "Step 2, Minibatch Loss= 2.6064, Training Accuracy= 0.625\n",
      "Step 3, Minibatch Loss= 0.6329, Training Accuracy= 0.648\n",
      "Step 4, Minibatch Loss= 1.4801, Training Accuracy= 0.398\n",
      "Step 5, Minibatch Loss= 0.7707, Training Accuracy= 0.492\n",
      "Step 6, Minibatch Loss= 0.5205, Training Accuracy= 0.719\n",
      "Step 7, Minibatch Loss= 0.9436, Training Accuracy= 0.594\n",
      "Step 8, Minibatch Loss= 0.7057, Training Accuracy= 0.664\n",
      "Step 9, Minibatch Loss= 0.6051, Training Accuracy= 0.617\n",
      "Step 10, Minibatch Loss= 0.5525, Training Accuracy= 0.695\n",
      "Step 11, Minibatch Loss= 0.6027, Training Accuracy= 0.789\n",
      "Step 12, Minibatch Loss= 0.5942, Training Accuracy= 0.656\n",
      "Step 13, Minibatch Loss= 0.6346, Training Accuracy= 0.617\n",
      "Step 14, Minibatch Loss= 0.5739, Training Accuracy= 0.703\n",
      "Step 15, Minibatch Loss= 0.5171, Training Accuracy= 0.734\n",
      "Step 16, Minibatch Loss= 0.6083, Training Accuracy= 0.695\n",
      "Step 17, Minibatch Loss= 0.4176, Training Accuracy= 0.781\n",
      "Step 18, Minibatch Loss= 0.4774, Training Accuracy= 0.758\n",
      "Step 19, Minibatch Loss= 0.5056, Training Accuracy= 0.781\n",
      "Step 20, Minibatch Loss= 0.6441, Training Accuracy= 0.750\n",
      "Step 21, Minibatch Loss= 0.4607, Training Accuracy= 0.695\n",
      "Step 22, Minibatch Loss= 0.4857, Training Accuracy= 0.742\n",
      "Step 23, Minibatch Loss= 0.5106, Training Accuracy= 0.773\n",
      "Step 24, Minibatch Loss= 0.4957, Training Accuracy= 0.719\n",
      "Step 25, Minibatch Loss= 0.5096, Training Accuracy= 0.781\n",
      "Step 26, Minibatch Loss= 0.4941, Training Accuracy= 0.711\n",
      "Step 27, Minibatch Loss= 0.4371, Training Accuracy= 0.773\n",
      "Step 28, Minibatch Loss= 0.5213, Training Accuracy= 0.781\n",
      "Step 29, Minibatch Loss= 0.5470, Training Accuracy= 0.727\n",
      "Step 30, Minibatch Loss= 0.4477, Training Accuracy= 0.812\n",
      "Step 31, Minibatch Loss= 0.4141, Training Accuracy= 0.844\n",
      "Step 32, Minibatch Loss= 0.3530, Training Accuracy= 0.875\n",
      "Step 33, Minibatch Loss= 0.3419, Training Accuracy= 0.875\n",
      "Step 34, Minibatch Loss= 0.3762, Training Accuracy= 0.812\n",
      "Step 35, Minibatch Loss= 0.4167, Training Accuracy= 0.852\n",
      "Step 36, Minibatch Loss= 0.3326, Training Accuracy= 0.852\n",
      "Step 37, Minibatch Loss= 0.4249, Training Accuracy= 0.797\n",
      "Step 38, Minibatch Loss= 0.3591, Training Accuracy= 0.844\n",
      "Step 39, Minibatch Loss= 0.3933, Training Accuracy= 0.812\n",
      "Step 40, Minibatch Loss= 0.3456, Training Accuracy= 0.906\n",
      "Step 41, Minibatch Loss= 0.3527, Training Accuracy= 0.859\n",
      "Step 42, Minibatch Loss= 0.3942, Training Accuracy= 0.852\n",
      "Step 43, Minibatch Loss= 0.3394, Training Accuracy= 0.883\n",
      "Step 44, Minibatch Loss= 0.3321, Training Accuracy= 0.852\n",
      "Step 45, Minibatch Loss= 0.3797, Training Accuracy= 0.875\n",
      "Step 46, Minibatch Loss= 0.2996, Training Accuracy= 0.875\n",
      "Step 47, Minibatch Loss= 0.3490, Training Accuracy= 0.859\n",
      "Step 48, Minibatch Loss= 0.2284, Training Accuracy= 0.914\n",
      "Step 49, Minibatch Loss= 0.2660, Training Accuracy= 0.875\n",
      "Step 50, Minibatch Loss= 0.2613, Training Accuracy= 0.898\n",
      "Step 51, Minibatch Loss= 0.2375, Training Accuracy= 0.914\n",
      "Step 52, Minibatch Loss= 0.2613, Training Accuracy= 0.883\n",
      "Step 53, Minibatch Loss= 0.3438, Training Accuracy= 0.859\n",
      "Step 54, Minibatch Loss= 0.3662, Training Accuracy= 0.852\n",
      "Step 55, Minibatch Loss= 0.2815, Training Accuracy= 0.883\n",
      "Step 56, Minibatch Loss= 0.3951, Training Accuracy= 0.812\n",
      "Step 57, Minibatch Loss= 0.3451, Training Accuracy= 0.867\n",
      "Step 58, Minibatch Loss= 0.1737, Training Accuracy= 0.930\n",
      "Step 59, Minibatch Loss= 0.2065, Training Accuracy= 0.922\n",
      "Step 60, Minibatch Loss= 0.2262, Training Accuracy= 0.945\n",
      "Step 61, Minibatch Loss= 0.2656, Training Accuracy= 0.891\n",
      "Step 62, Minibatch Loss= 0.2630, Training Accuracy= 0.953\n",
      "Step 63, Minibatch Loss= 0.2936, Training Accuracy= 0.906\n",
      "Step 64, Minibatch Loss= 0.2379, Training Accuracy= 0.883\n",
      "Step 65, Minibatch Loss= 0.2911, Training Accuracy= 0.883\n",
      "Step 66, Minibatch Loss= 0.2307, Training Accuracy= 0.875\n",
      "Step 67, Minibatch Loss= 0.3108, Training Accuracy= 0.914\n",
      "Step 68, Minibatch Loss= 0.3634, Training Accuracy= 0.867\n",
      "Step 69, Minibatch Loss= 0.2453, Training Accuracy= 0.922\n",
      "Step 70, Minibatch Loss= 0.2792, Training Accuracy= 0.930\n",
      "Step 71, Minibatch Loss= 0.2158, Training Accuracy= 0.914\n",
      "Step 72, Minibatch Loss= 0.2810, Training Accuracy= 0.883\n",
      "Step 73, Minibatch Loss= 0.3245, Training Accuracy= 0.867\n",
      "Step 74, Minibatch Loss= 0.2099, Training Accuracy= 0.930\n",
      "Step 75, Minibatch Loss= 0.3237, Training Accuracy= 0.859\n",
      "Step 76, Minibatch Loss= 0.1767, Training Accuracy= 0.930\n",
      "Step 77, Minibatch Loss= 0.2774, Training Accuracy= 0.898\n",
      "Step 78, Minibatch Loss= 0.3155, Training Accuracy= 0.891\n",
      "Step 79, Minibatch Loss= 0.2697, Training Accuracy= 0.938\n",
      "Step 80, Minibatch Loss= 0.1653, Training Accuracy= 0.945\n",
      "Step 81, Minibatch Loss= 0.2726, Training Accuracy= 0.891\n",
      "Step 82, Minibatch Loss= 0.2555, Training Accuracy= 0.906\n",
      "Step 83, Minibatch Loss= 0.2390, Training Accuracy= 0.891\n",
      "Step 84, Minibatch Loss= 0.2453, Training Accuracy= 0.891\n",
      "Step 85, Minibatch Loss= 0.2925, Training Accuracy= 0.875\n",
      "Step 86, Minibatch Loss= 0.2473, Training Accuracy= 0.914\n",
      "Step 87, Minibatch Loss= 0.1410, Training Accuracy= 0.977\n",
      "Step 88, Minibatch Loss= 0.2153, Training Accuracy= 0.945\n",
      "Step 89, Minibatch Loss= 0.1865, Training Accuracy= 0.938\n",
      "Step 90, Minibatch Loss= 0.2146, Training Accuracy= 0.938\n",
      "Step 91, Minibatch Loss= 0.2992, Training Accuracy= 0.891\n",
      "Step 92, Minibatch Loss= 0.1837, Training Accuracy= 0.922\n",
      "Step 93, Minibatch Loss= 0.3264, Training Accuracy= 0.906\n",
      "Step 94, Minibatch Loss= 0.3090, Training Accuracy= 0.883\n",
      "Step 95, Minibatch Loss= 0.1883, Training Accuracy= 0.930\n",
      "Step 96, Minibatch Loss= 0.2691, Training Accuracy= 0.875\n",
      "Step 97, Minibatch Loss= 0.2455, Training Accuracy= 0.898\n",
      "Step 98, Minibatch Loss= 0.2542, Training Accuracy= 0.914\n",
      "Step 99, Minibatch Loss= 0.2041, Training Accuracy= 0.953\n",
      "Step 100, Minibatch Loss= 0.1914, Training Accuracy= 0.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 101, Minibatch Loss= 0.1511, Training Accuracy= 0.961\n",
      "Step 102, Minibatch Loss= 0.2254, Training Accuracy= 0.898\n",
      "Step 103, Minibatch Loss= 0.1749, Training Accuracy= 0.938\n",
      "Step 104, Minibatch Loss= 0.1557, Training Accuracy= 0.977\n",
      "Step 105, Minibatch Loss= 0.1869, Training Accuracy= 0.961\n",
      "Step 106, Minibatch Loss= 0.2275, Training Accuracy= 0.922\n",
      "Step 107, Minibatch Loss= 0.1712, Training Accuracy= 0.930\n",
      "Step 108, Minibatch Loss= 0.2512, Training Accuracy= 0.898\n",
      "Step 109, Minibatch Loss= 0.1825, Training Accuracy= 0.945\n",
      "Step 110, Minibatch Loss= 0.2212, Training Accuracy= 0.906\n",
      "Step 111, Minibatch Loss= 0.1164, Training Accuracy= 0.953\n",
      "Step 112, Minibatch Loss= 0.1801, Training Accuracy= 0.961\n",
      "Step 113, Minibatch Loss= 0.2045, Training Accuracy= 0.930\n",
      "Step 114, Minibatch Loss= 0.1443, Training Accuracy= 0.953\n",
      "Step 115, Minibatch Loss= 0.1166, Training Accuracy= 0.969\n",
      "Step 116, Minibatch Loss= 0.1369, Training Accuracy= 0.953\n",
      "Step 117, Minibatch Loss= 0.1506, Training Accuracy= 0.945\n",
      "Step 118, Minibatch Loss= 0.2200, Training Accuracy= 0.891\n",
      "Step 119, Minibatch Loss= 0.1699, Training Accuracy= 0.930\n",
      "Step 120, Minibatch Loss= 0.1296, Training Accuracy= 0.930\n",
      "Step 121, Minibatch Loss= 0.1382, Training Accuracy= 0.953\n",
      "Step 122, Minibatch Loss= 0.1533, Training Accuracy= 0.945\n",
      "Step 123, Minibatch Loss= 0.1398, Training Accuracy= 0.945\n",
      "Step 124, Minibatch Loss= 0.1455, Training Accuracy= 0.953\n",
      "Step 125, Minibatch Loss= 0.0804, Training Accuracy= 0.969\n",
      "Step 126, Minibatch Loss= 0.1033, Training Accuracy= 0.953\n",
      "Step 127, Minibatch Loss= 0.1192, Training Accuracy= 0.961\n",
      "Step 128, Minibatch Loss= 0.0988, Training Accuracy= 0.953\n",
      "Step 129, Minibatch Loss= 0.1951, Training Accuracy= 0.953\n",
      "Step 130, Minibatch Loss= 0.1068, Training Accuracy= 0.977\n",
      "Step 131, Minibatch Loss= 0.2013, Training Accuracy= 0.953\n",
      "Step 132, Minibatch Loss= 0.2917, Training Accuracy= 0.914\n",
      "Step 133, Minibatch Loss= 0.1151, Training Accuracy= 0.961\n",
      "Step 134, Minibatch Loss= 0.3996, Training Accuracy= 0.875\n",
      "Step 135, Minibatch Loss= 0.1496, Training Accuracy= 0.945\n",
      "Step 136, Minibatch Loss= 0.1289, Training Accuracy= 0.930\n",
      "Step 137, Minibatch Loss= 0.1254, Training Accuracy= 0.961\n",
      "Step 138, Minibatch Loss= 0.0789, Training Accuracy= 0.984\n",
      "Step 139, Minibatch Loss= 0.2344, Training Accuracy= 0.945\n",
      "Step 140, Minibatch Loss= 0.3995, Training Accuracy= 0.836\n",
      "Step 141, Minibatch Loss= 0.0913, Training Accuracy= 0.961\n",
      "Step 142, Minibatch Loss= 0.1427, Training Accuracy= 0.938\n",
      "Step 143, Minibatch Loss= 0.1247, Training Accuracy= 0.945\n",
      "Step 144, Minibatch Loss= 0.1745, Training Accuracy= 0.945\n",
      "Step 145, Minibatch Loss= 0.1454, Training Accuracy= 0.938\n",
      "Step 146, Minibatch Loss= 0.1728, Training Accuracy= 0.938\n",
      "Step 147, Minibatch Loss= 0.1964, Training Accuracy= 0.906\n",
      "Step 148, Minibatch Loss= 0.1419, Training Accuracy= 0.945\n",
      "Step 149, Minibatch Loss= 0.1245, Training Accuracy= 0.938\n",
      "Step 150, Minibatch Loss= 0.2620, Training Accuracy= 0.922\n",
      "Step 151, Minibatch Loss= 0.1540, Training Accuracy= 0.938\n",
      "Step 152, Minibatch Loss= 0.1205, Training Accuracy= 0.969\n",
      "Step 153, Minibatch Loss= 0.2540, Training Accuracy= 0.906\n",
      "Step 154, Minibatch Loss= 0.1333, Training Accuracy= 0.945\n",
      "Step 155, Minibatch Loss= 0.3112, Training Accuracy= 0.914\n",
      "Step 156, Minibatch Loss= 0.1377, Training Accuracy= 0.945\n",
      "Step 157, Minibatch Loss= 0.1158, Training Accuracy= 0.977\n",
      "Step 158, Minibatch Loss= 0.1028, Training Accuracy= 0.969\n",
      "Step 159, Minibatch Loss= 0.1416, Training Accuracy= 0.953\n",
      "Step 160, Minibatch Loss= 0.1354, Training Accuracy= 0.945\n",
      "Step 161, Minibatch Loss= 0.1296, Training Accuracy= 0.961\n",
      "Step 162, Minibatch Loss= 0.1855, Training Accuracy= 0.961\n",
      "Step 163, Minibatch Loss= 0.1666, Training Accuracy= 0.930\n",
      "Step 164, Minibatch Loss= 0.1264, Training Accuracy= 0.961\n",
      "Step 165, Minibatch Loss= 0.1659, Training Accuracy= 0.930\n",
      "Step 166, Minibatch Loss= 0.1304, Training Accuracy= 0.938\n",
      "Step 167, Minibatch Loss= 0.1754, Training Accuracy= 0.938\n",
      "Step 168, Minibatch Loss= 0.2950, Training Accuracy= 0.906\n",
      "Step 169, Minibatch Loss= 0.1129, Training Accuracy= 0.969\n",
      "Step 170, Minibatch Loss= 0.1310, Training Accuracy= 0.938\n",
      "Step 171, Minibatch Loss= 0.1810, Training Accuracy= 0.961\n",
      "Step 172, Minibatch Loss= 0.0832, Training Accuracy= 0.977\n",
      "Step 173, Minibatch Loss= 0.2029, Training Accuracy= 0.938\n",
      "Step 174, Minibatch Loss= 0.1576, Training Accuracy= 0.977\n",
      "Step 175, Minibatch Loss= 0.1533, Training Accuracy= 0.977\n",
      "Step 176, Minibatch Loss= 0.1731, Training Accuracy= 0.945\n",
      "Step 177, Minibatch Loss= 0.1587, Training Accuracy= 0.938\n",
      "Step 178, Minibatch Loss= 0.1797, Training Accuracy= 0.914\n",
      "Step 179, Minibatch Loss= 0.0926, Training Accuracy= 0.969\n",
      "Step 180, Minibatch Loss= 0.2112, Training Accuracy= 0.930\n",
      "Step 181, Minibatch Loss= 0.1369, Training Accuracy= 0.953\n",
      "Step 182, Minibatch Loss= 0.1370, Training Accuracy= 0.961\n",
      "Step 183, Minibatch Loss= 0.1043, Training Accuracy= 0.969\n",
      "Step 184, Minibatch Loss= 0.2238, Training Accuracy= 0.930\n",
      "Step 185, Minibatch Loss= 0.2412, Training Accuracy= 0.938\n",
      "Step 186, Minibatch Loss= 0.2811, Training Accuracy= 0.898\n",
      "Step 187, Minibatch Loss= 0.2025, Training Accuracy= 0.953\n",
      "Step 188, Minibatch Loss= 0.1082, Training Accuracy= 0.961\n",
      "Step 189, Minibatch Loss= 0.1466, Training Accuracy= 0.953\n",
      "Step 190, Minibatch Loss= 0.1558, Training Accuracy= 0.938\n",
      "Step 191, Minibatch Loss= 0.1640, Training Accuracy= 0.961\n",
      "Step 192, Minibatch Loss= 0.1544, Training Accuracy= 0.938\n",
      "Step 193, Minibatch Loss= 0.2258, Training Accuracy= 0.906\n",
      "Step 194, Minibatch Loss= 0.1420, Training Accuracy= 0.961\n",
      "Step 195, Minibatch Loss= 0.1744, Training Accuracy= 0.945\n",
      "Step 196, Minibatch Loss= 0.1236, Training Accuracy= 0.961\n",
      "Step 197, Minibatch Loss= 0.1597, Training Accuracy= 0.938\n",
      "Step 198, Minibatch Loss= 0.1333, Training Accuracy= 0.969\n",
      "Step 199, Minibatch Loss= 0.1036, Training Accuracy= 0.969\n",
      "Step 200, Minibatch Loss= 0.2174, Training Accuracy= 0.945\n",
      "Step 201, Minibatch Loss= 0.1098, Training Accuracy= 0.969\n",
      "Step 202, Minibatch Loss= 0.1387, Training Accuracy= 0.930\n",
      "Step 203, Minibatch Loss= 0.1313, Training Accuracy= 0.953\n",
      "Step 204, Minibatch Loss= 0.1792, Training Accuracy= 0.938\n",
      "Step 205, Minibatch Loss= 0.2492, Training Accuracy= 0.914\n",
      "Step 206, Minibatch Loss= 0.2511, Training Accuracy= 0.898\n",
      "Step 207, Minibatch Loss= 0.1536, Training Accuracy= 0.930\n",
      "Step 208, Minibatch Loss= 0.0580, Training Accuracy= 0.984\n",
      "Step 209, Minibatch Loss= 0.1500, Training Accuracy= 0.945\n",
      "Step 210, Minibatch Loss= 0.1487, Training Accuracy= 0.953\n",
      "Step 211, Minibatch Loss= 0.1321, Training Accuracy= 0.945\n",
      "Step 212, Minibatch Loss= 0.1185, Training Accuracy= 0.953\n",
      "Step 213, Minibatch Loss= 0.2651, Training Accuracy= 0.898\n",
      "Step 214, Minibatch Loss= 0.1111, Training Accuracy= 0.961\n",
      "Step 215, Minibatch Loss= 0.1265, Training Accuracy= 0.969\n",
      "Step 216, Minibatch Loss= 0.1356, Training Accuracy= 0.961\n",
      "Step 217, Minibatch Loss= 0.0971, Training Accuracy= 0.969\n",
      "Step 218, Minibatch Loss= 0.1479, Training Accuracy= 0.938\n",
      "Step 219, Minibatch Loss= 0.1751, Training Accuracy= 0.930\n",
      "Step 220, Minibatch Loss= 0.1530, Training Accuracy= 0.961\n",
      "Step 221, Minibatch Loss= 0.1475, Training Accuracy= 0.953\n",
      "Step 222, Minibatch Loss= 0.1360, Training Accuracy= 0.953\n",
      "Step 223, Minibatch Loss= 0.2222, Training Accuracy= 0.938\n",
      "Step 224, Minibatch Loss= 0.1295, Training Accuracy= 0.945\n",
      "Step 225, Minibatch Loss= 0.1591, Training Accuracy= 0.945\n",
      "Step 226, Minibatch Loss= 0.1444, Training Accuracy= 0.938\n",
      "Step 227, Minibatch Loss= 0.0758, Training Accuracy= 0.984\n",
      "Step 228, Minibatch Loss= 0.2005, Training Accuracy= 0.906\n",
      "Step 229, Minibatch Loss= 0.0839, Training Accuracy= 0.977\n",
      "Step 230, Minibatch Loss= 0.0991, Training Accuracy= 0.969\n",
      "Step 231, Minibatch Loss= 0.1797, Training Accuracy= 0.922\n",
      "Step 232, Minibatch Loss= 0.0870, Training Accuracy= 0.977\n",
      "Step 233, Minibatch Loss= 0.0726, Training Accuracy= 0.977\n",
      "Step 234, Minibatch Loss= 0.2190, Training Accuracy= 0.953\n",
      "Step 235, Minibatch Loss= 0.1985, Training Accuracy= 0.922\n",
      "Step 236, Minibatch Loss= 0.2106, Training Accuracy= 0.938\n",
      "Step 237, Minibatch Loss= 0.1825, Training Accuracy= 0.930\n",
      "Step 238, Minibatch Loss= 0.1303, Training Accuracy= 0.961\n",
      "Step 239, Minibatch Loss= 0.1163, Training Accuracy= 0.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 240, Minibatch Loss= 0.1027, Training Accuracy= 0.961\n",
      "Step 241, Minibatch Loss= 0.1816, Training Accuracy= 0.930\n",
      "Step 242, Minibatch Loss= 0.1536, Training Accuracy= 0.938\n",
      "Step 243, Minibatch Loss= 0.1568, Training Accuracy= 0.938\n",
      "Step 244, Minibatch Loss= 0.0967, Training Accuracy= 0.969\n",
      "Step 245, Minibatch Loss= 0.1362, Training Accuracy= 0.953\n",
      "Step 246, Minibatch Loss= 0.2085, Training Accuracy= 0.945\n",
      "Step 247, Minibatch Loss= 0.1015, Training Accuracy= 0.984\n",
      "Step 248, Minibatch Loss= 0.0925, Training Accuracy= 0.977\n",
      "Step 249, Minibatch Loss= 0.1475, Training Accuracy= 0.953\n",
      "Step 250, Minibatch Loss= 0.1062, Training Accuracy= 0.953\n",
      "Step 251, Minibatch Loss= 0.1793, Training Accuracy= 0.930\n",
      "Step 252, Minibatch Loss= 0.1450, Training Accuracy= 0.945\n",
      "Step 253, Minibatch Loss= 0.1578, Training Accuracy= 0.930\n",
      "Step 254, Minibatch Loss= 0.2174, Training Accuracy= 0.906\n",
      "Step 255, Minibatch Loss= 0.1729, Training Accuracy= 0.938\n",
      "Step 256, Minibatch Loss= 0.1250, Training Accuracy= 0.938\n",
      "Step 257, Minibatch Loss= 0.1722, Training Accuracy= 0.914\n",
      "Step 258, Minibatch Loss= 0.2473, Training Accuracy= 0.922\n",
      "Step 259, Minibatch Loss= 0.1005, Training Accuracy= 0.961\n",
      "Step 260, Minibatch Loss= 0.1225, Training Accuracy= 0.945\n",
      "Step 261, Minibatch Loss= 0.1478, Training Accuracy= 0.953\n",
      "Step 262, Minibatch Loss= 0.2368, Training Accuracy= 0.953\n",
      "Step 263, Minibatch Loss= 0.1505, Training Accuracy= 0.938\n",
      "Step 264, Minibatch Loss= 0.2068, Training Accuracy= 0.922\n",
      "Step 265, Minibatch Loss= 0.2484, Training Accuracy= 0.906\n",
      "Step 266, Minibatch Loss= 0.1236, Training Accuracy= 0.953\n",
      "Step 267, Minibatch Loss= 0.1434, Training Accuracy= 0.938\n",
      "Step 268, Minibatch Loss= 0.1426, Training Accuracy= 0.938\n",
      "Step 269, Minibatch Loss= 0.1307, Training Accuracy= 0.945\n",
      "Step 270, Minibatch Loss= 0.1814, Training Accuracy= 0.953\n",
      "Step 271, Minibatch Loss= 0.1016, Training Accuracy= 0.969\n",
      "Step 272, Minibatch Loss= 0.1668, Training Accuracy= 0.945\n",
      "Step 273, Minibatch Loss= 0.1470, Training Accuracy= 0.930\n",
      "Step 274, Minibatch Loss= 0.2161, Training Accuracy= 0.953\n",
      "Step 275, Minibatch Loss= 0.1681, Training Accuracy= 0.930\n",
      "Step 276, Minibatch Loss= 0.0887, Training Accuracy= 0.969\n",
      "Step 277, Minibatch Loss= 0.2173, Training Accuracy= 0.914\n",
      "Step 278, Minibatch Loss= 0.1660, Training Accuracy= 0.938\n",
      "Step 279, Minibatch Loss= 0.1259, Training Accuracy= 0.953\n",
      "Step 280, Minibatch Loss= 0.2307, Training Accuracy= 0.938\n",
      "Step 281, Minibatch Loss= 0.1308, Training Accuracy= 0.953\n",
      "Step 282, Minibatch Loss= 0.1182, Training Accuracy= 0.969\n",
      "Step 283, Minibatch Loss= 0.1488, Training Accuracy= 0.953\n",
      "Step 284, Minibatch Loss= 0.1414, Training Accuracy= 0.938\n",
      "Step 285, Minibatch Loss= 0.0816, Training Accuracy= 0.977\n",
      "Step 286, Minibatch Loss= 0.1581, Training Accuracy= 0.930\n",
      "Step 287, Minibatch Loss= 0.2485, Training Accuracy= 0.906\n",
      "Step 288, Minibatch Loss= 0.1884, Training Accuracy= 0.945\n",
      "Step 289, Minibatch Loss= 0.1166, Training Accuracy= 0.969\n",
      "Step 290, Minibatch Loss= 0.1482, Training Accuracy= 0.969\n",
      "Step 291, Minibatch Loss= 0.0913, Training Accuracy= 0.953\n",
      "Step 292, Minibatch Loss= 0.1846, Training Accuracy= 0.938\n",
      "Step 293, Minibatch Loss= 0.1258, Training Accuracy= 0.945\n",
      "Step 294, Minibatch Loss= 0.1809, Training Accuracy= 0.945\n",
      "Step 295, Minibatch Loss= 0.1444, Training Accuracy= 0.945\n",
      "Step 296, Minibatch Loss= 0.1967, Training Accuracy= 0.961\n",
      "Step 297, Minibatch Loss= 0.2201, Training Accuracy= 0.914\n",
      "Step 298, Minibatch Loss= 0.1722, Training Accuracy= 0.938\n",
      "Step 299, Minibatch Loss= 0.1993, Training Accuracy= 0.906\n",
      "Step 300, Minibatch Loss= 0.2407, Training Accuracy= 0.922\n",
      "Step 301, Minibatch Loss= 0.1168, Training Accuracy= 0.977\n",
      "Step 302, Minibatch Loss= 0.1303, Training Accuracy= 0.945\n",
      "Step 303, Minibatch Loss= 0.1558, Training Accuracy= 0.969\n",
      "Step 304, Minibatch Loss= 0.1324, Training Accuracy= 0.961\n",
      "Step 305, Minibatch Loss= 0.1853, Training Accuracy= 0.953\n",
      "Step 306, Minibatch Loss= 0.2320, Training Accuracy= 0.961\n",
      "Step 307, Minibatch Loss= 0.1590, Training Accuracy= 0.961\n",
      "Step 308, Minibatch Loss= 0.2220, Training Accuracy= 0.898\n",
      "Step 309, Minibatch Loss= 0.1064, Training Accuracy= 0.945\n",
      "Step 310, Minibatch Loss= 0.1211, Training Accuracy= 0.953\n",
      "Step 311, Minibatch Loss= 0.1202, Training Accuracy= 0.961\n",
      "Step 312, Minibatch Loss= 0.1395, Training Accuracy= 0.945\n",
      "Step 313, Minibatch Loss= 0.1228, Training Accuracy= 0.969\n",
      "Step 314, Minibatch Loss= 0.1793, Training Accuracy= 0.930\n",
      "Step 315, Minibatch Loss= 0.1382, Training Accuracy= 0.953\n",
      "Step 316, Minibatch Loss= 0.1871, Training Accuracy= 0.938\n",
      "Step 317, Minibatch Loss= 0.1233, Training Accuracy= 0.945\n",
      "Step 318, Minibatch Loss= 0.1370, Training Accuracy= 0.945\n",
      "Step 319, Minibatch Loss= 0.2173, Training Accuracy= 0.930\n",
      "Step 320, Minibatch Loss= 0.2412, Training Accuracy= 0.906\n",
      "Step 321, Minibatch Loss= 0.1139, Training Accuracy= 0.969\n",
      "Step 322, Minibatch Loss= 0.1781, Training Accuracy= 0.945\n",
      "Step 323, Minibatch Loss= 0.1456, Training Accuracy= 0.961\n",
      "Step 324, Minibatch Loss= 0.1575, Training Accuracy= 0.938\n",
      "Step 325, Minibatch Loss= 0.1561, Training Accuracy= 0.938\n",
      "Step 326, Minibatch Loss= 0.1161, Training Accuracy= 0.969\n",
      "Step 327, Minibatch Loss= 0.3116, Training Accuracy= 0.922\n",
      "Step 328, Minibatch Loss= 0.1262, Training Accuracy= 0.945\n",
      "Step 329, Minibatch Loss= 0.2129, Training Accuracy= 0.930\n",
      "Step 330, Minibatch Loss= 0.1315, Training Accuracy= 0.969\n",
      "Step 331, Minibatch Loss= 0.2071, Training Accuracy= 0.930\n",
      "Step 332, Minibatch Loss= 0.1193, Training Accuracy= 0.961\n",
      "Step 333, Minibatch Loss= 0.1763, Training Accuracy= 0.945\n",
      "Step 334, Minibatch Loss= 0.1321, Training Accuracy= 0.969\n",
      "Step 335, Minibatch Loss= 0.1055, Training Accuracy= 0.969\n",
      "Step 336, Minibatch Loss= 0.1416, Training Accuracy= 0.961\n",
      "Step 337, Minibatch Loss= 0.1435, Training Accuracy= 0.961\n",
      "Step 338, Minibatch Loss= 0.1347, Training Accuracy= 0.961\n",
      "Step 339, Minibatch Loss= 0.1070, Training Accuracy= 0.953\n",
      "Step 340, Minibatch Loss= 0.0656, Training Accuracy= 0.992\n",
      "Step 341, Minibatch Loss= 0.2059, Training Accuracy= 0.945\n",
      "Step 342, Minibatch Loss= 0.1289, Training Accuracy= 0.969\n",
      "Step 343, Minibatch Loss= 0.2774, Training Accuracy= 0.945\n",
      "Step 344, Minibatch Loss= 0.2443, Training Accuracy= 0.906\n",
      "Step 345, Minibatch Loss= 0.1081, Training Accuracy= 0.961\n",
      "Step 346, Minibatch Loss= 0.1459, Training Accuracy= 0.953\n",
      "Step 347, Minibatch Loss= 0.1482, Training Accuracy= 0.930\n",
      "Step 348, Minibatch Loss= 0.2164, Training Accuracy= 0.914\n",
      "Step 349, Minibatch Loss= 0.2030, Training Accuracy= 0.953\n",
      "Step 350, Minibatch Loss= 0.0921, Training Accuracy= 0.984\n",
      "Step 351, Minibatch Loss= 0.2232, Training Accuracy= 0.945\n",
      "Step 352, Minibatch Loss= 0.1137, Training Accuracy= 0.969\n",
      "Step 353, Minibatch Loss= 0.1334, Training Accuracy= 0.969\n",
      "Step 354, Minibatch Loss= 0.1070, Training Accuracy= 0.977\n",
      "Step 355, Minibatch Loss= 0.0940, Training Accuracy= 0.961\n",
      "Step 356, Minibatch Loss= 0.0782, Training Accuracy= 0.961\n",
      "Step 357, Minibatch Loss= 0.1708, Training Accuracy= 0.922\n",
      "Step 358, Minibatch Loss= 0.1131, Training Accuracy= 0.953\n",
      "Step 359, Minibatch Loss= 0.0921, Training Accuracy= 0.969\n",
      "Step 360, Minibatch Loss= 0.1488, Training Accuracy= 0.945\n",
      "Step 361, Minibatch Loss= 0.3048, Training Accuracy= 0.906\n",
      "Step 362, Minibatch Loss= 0.1201, Training Accuracy= 0.961\n",
      "Step 363, Minibatch Loss= 0.1036, Training Accuracy= 0.969\n",
      "Step 364, Minibatch Loss= 0.1427, Training Accuracy= 0.945\n",
      "Step 365, Minibatch Loss= 0.1758, Training Accuracy= 0.906\n",
      "Step 366, Minibatch Loss= 0.1830, Training Accuracy= 0.914\n",
      "Step 367, Minibatch Loss= 0.1098, Training Accuracy= 0.969\n",
      "Step 368, Minibatch Loss= 0.1235, Training Accuracy= 0.945\n",
      "Step 369, Minibatch Loss= 0.1398, Training Accuracy= 0.945\n",
      "Step 370, Minibatch Loss= 0.1441, Training Accuracy= 0.953\n",
      "Step 371, Minibatch Loss= 0.0987, Training Accuracy= 0.969\n",
      "Step 372, Minibatch Loss= 0.1611, Training Accuracy= 0.938\n",
      "Step 373, Minibatch Loss= 0.1720, Training Accuracy= 0.945\n",
      "Step 374, Minibatch Loss= 0.0370, Training Accuracy= 0.992\n",
      "Step 375, Minibatch Loss= 0.1218, Training Accuracy= 0.961\n",
      "Step 376, Minibatch Loss= 0.2702, Training Accuracy= 0.938\n",
      "Step 377, Minibatch Loss= 0.1129, Training Accuracy= 0.961\n",
      "Step 378, Minibatch Loss= 0.2584, Training Accuracy= 0.922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 379, Minibatch Loss= 0.1280, Training Accuracy= 0.945\n",
      "Step 380, Minibatch Loss= 0.1520, Training Accuracy= 0.953\n",
      "Step 381, Minibatch Loss= 0.2101, Training Accuracy= 0.938\n",
      "Step 382, Minibatch Loss= 0.1772, Training Accuracy= 0.930\n",
      "Step 383, Minibatch Loss= 0.1090, Training Accuracy= 0.953\n",
      "Step 384, Minibatch Loss= 0.1548, Training Accuracy= 0.938\n",
      "Step 385, Minibatch Loss= 0.1076, Training Accuracy= 0.953\n",
      "Step 386, Minibatch Loss= 0.1382, Training Accuracy= 0.922\n",
      "Step 387, Minibatch Loss= 0.1623, Training Accuracy= 0.945\n",
      "Step 388, Minibatch Loss= 0.1094, Training Accuracy= 0.961\n",
      "Step 389, Minibatch Loss= 0.1058, Training Accuracy= 0.961\n",
      "Step 390, Minibatch Loss= 0.1969, Training Accuracy= 0.930\n",
      "Step 391, Minibatch Loss= 0.1412, Training Accuracy= 0.977\n",
      "Step 392, Minibatch Loss= 0.0818, Training Accuracy= 0.977\n",
      "Step 393, Minibatch Loss= 0.1633, Training Accuracy= 0.930\n",
      "Step 394, Minibatch Loss= 0.0725, Training Accuracy= 0.984\n",
      "Step 395, Minibatch Loss= 0.2338, Training Accuracy= 0.922\n",
      "Step 396, Minibatch Loss= 0.1193, Training Accuracy= 0.969\n",
      "Step 397, Minibatch Loss= 0.1451, Training Accuracy= 0.945\n",
      "Step 398, Minibatch Loss= 0.2261, Training Accuracy= 0.922\n",
      "Step 399, Minibatch Loss= 0.1976, Training Accuracy= 0.914\n",
      "Step 400, Minibatch Loss= 0.1239, Training Accuracy= 0.953\n",
      "Step 401, Minibatch Loss= 0.1492, Training Accuracy= 0.969\n",
      "Step 402, Minibatch Loss= 0.2054, Training Accuracy= 0.914\n",
      "Step 403, Minibatch Loss= 0.1170, Training Accuracy= 0.961\n",
      "Step 404, Minibatch Loss= 0.0967, Training Accuracy= 0.977\n",
      "Step 405, Minibatch Loss= 0.2006, Training Accuracy= 0.938\n",
      "Step 406, Minibatch Loss= 0.1197, Training Accuracy= 0.961\n",
      "Step 407, Minibatch Loss= 0.1178, Training Accuracy= 0.953\n",
      "Step 408, Minibatch Loss= 0.1797, Training Accuracy= 0.922\n",
      "Step 409, Minibatch Loss= 0.1467, Training Accuracy= 0.945\n",
      "Step 410, Minibatch Loss= 0.1087, Training Accuracy= 0.961\n",
      "Step 411, Minibatch Loss= 0.2097, Training Accuracy= 0.938\n",
      "Step 412, Minibatch Loss= 0.1425, Training Accuracy= 0.945\n",
      "Step 413, Minibatch Loss= 0.1832, Training Accuracy= 0.938\n",
      "Step 414, Minibatch Loss= 0.1259, Training Accuracy= 0.953\n",
      "Step 415, Minibatch Loss= 0.1744, Training Accuracy= 0.945\n",
      "Step 416, Minibatch Loss= 0.0672, Training Accuracy= 0.984\n",
      "Step 417, Minibatch Loss= 0.1858, Training Accuracy= 0.969\n",
      "Step 418, Minibatch Loss= 0.1323, Training Accuracy= 0.969\n",
      "Step 419, Minibatch Loss= 0.1295, Training Accuracy= 0.938\n",
      "Step 420, Minibatch Loss= 0.1303, Training Accuracy= 0.969\n",
      "Step 421, Minibatch Loss= 0.1106, Training Accuracy= 0.961\n",
      "Step 422, Minibatch Loss= 0.1339, Training Accuracy= 0.969\n",
      "Step 423, Minibatch Loss= 0.0875, Training Accuracy= 0.969\n",
      "Step 424, Minibatch Loss= 0.1780, Training Accuracy= 0.930\n",
      "Step 425, Minibatch Loss= 0.1109, Training Accuracy= 0.961\n",
      "Step 426, Minibatch Loss= 0.1181, Training Accuracy= 0.961\n",
      "Step 427, Minibatch Loss= 0.2866, Training Accuracy= 0.922\n",
      "Step 428, Minibatch Loss= 0.2481, Training Accuracy= 0.930\n",
      "Step 429, Minibatch Loss= 0.1884, Training Accuracy= 0.922\n",
      "Step 430, Minibatch Loss= 0.1261, Training Accuracy= 0.961\n",
      "Step 431, Minibatch Loss= 0.1940, Training Accuracy= 0.930\n",
      "Step 432, Minibatch Loss= 0.1539, Training Accuracy= 0.930\n",
      "Step 433, Minibatch Loss= 0.1353, Training Accuracy= 0.953\n",
      "Step 434, Minibatch Loss= 0.1374, Training Accuracy= 0.938\n",
      "Step 435, Minibatch Loss= 0.2166, Training Accuracy= 0.945\n",
      "Step 436, Minibatch Loss= 0.1564, Training Accuracy= 0.961\n",
      "Step 437, Minibatch Loss= 0.1491, Training Accuracy= 0.938\n",
      "Step 438, Minibatch Loss= 0.1688, Training Accuracy= 0.938\n",
      "Step 439, Minibatch Loss= 0.1499, Training Accuracy= 0.945\n",
      "Step 440, Minibatch Loss= 0.1747, Training Accuracy= 0.930\n",
      "Step 441, Minibatch Loss= 0.0580, Training Accuracy= 0.984\n",
      "Step 442, Minibatch Loss= 0.0928, Training Accuracy= 0.969\n",
      "Step 443, Minibatch Loss= 0.2359, Training Accuracy= 0.930\n",
      "Step 444, Minibatch Loss= 0.1441, Training Accuracy= 0.945\n",
      "Step 445, Minibatch Loss= 0.0965, Training Accuracy= 0.961\n",
      "Step 446, Minibatch Loss= 0.2380, Training Accuracy= 0.945\n",
      "Step 447, Minibatch Loss= 0.1446, Training Accuracy= 0.953\n",
      "Step 448, Minibatch Loss= 0.1135, Training Accuracy= 0.961\n",
      "Step 449, Minibatch Loss= 0.0840, Training Accuracy= 0.969\n",
      "Step 450, Minibatch Loss= 0.2015, Training Accuracy= 0.953\n",
      "Step 451, Minibatch Loss= 0.2436, Training Accuracy= 0.938\n",
      "Step 452, Minibatch Loss= 0.1409, Training Accuracy= 0.945\n",
      "Step 453, Minibatch Loss= 0.1569, Training Accuracy= 0.930\n",
      "Step 454, Minibatch Loss= 0.1130, Training Accuracy= 0.977\n",
      "Step 455, Minibatch Loss= 0.0704, Training Accuracy= 0.977\n",
      "Step 456, Minibatch Loss= 0.1563, Training Accuracy= 0.930\n",
      "Step 457, Minibatch Loss= 0.1377, Training Accuracy= 0.969\n",
      "Step 458, Minibatch Loss= 0.0566, Training Accuracy= 0.984\n",
      "Step 459, Minibatch Loss= 0.1881, Training Accuracy= 0.930\n",
      "Step 460, Minibatch Loss= 0.2093, Training Accuracy= 0.945\n",
      "Step 461, Minibatch Loss= 0.1001, Training Accuracy= 0.977\n",
      "Step 462, Minibatch Loss= 0.1315, Training Accuracy= 0.953\n",
      "Step 463, Minibatch Loss= 0.1146, Training Accuracy= 0.969\n",
      "Step 464, Minibatch Loss= 0.0932, Training Accuracy= 0.969\n",
      "Step 465, Minibatch Loss= 0.1805, Training Accuracy= 0.938\n",
      "Step 466, Minibatch Loss= 0.1722, Training Accuracy= 0.961\n",
      "Step 467, Minibatch Loss= 0.1340, Training Accuracy= 0.953\n",
      "Step 468, Minibatch Loss= 0.1034, Training Accuracy= 0.961\n",
      "Step 469, Minibatch Loss= 0.1772, Training Accuracy= 0.922\n",
      "Step 470, Minibatch Loss= 0.1201, Training Accuracy= 0.961\n",
      "Step 471, Minibatch Loss= 0.2192, Training Accuracy= 0.914\n",
      "Step 472, Minibatch Loss= 0.1487, Training Accuracy= 0.961\n",
      "Step 473, Minibatch Loss= 0.2112, Training Accuracy= 0.938\n",
      "Step 474, Minibatch Loss= 0.1206, Training Accuracy= 0.945\n",
      "Step 475, Minibatch Loss= 0.0737, Training Accuracy= 0.984\n",
      "Step 476, Minibatch Loss= 0.1299, Training Accuracy= 0.961\n",
      "Step 477, Minibatch Loss= 0.0847, Training Accuracy= 0.977\n",
      "Step 478, Minibatch Loss= 0.1995, Training Accuracy= 0.930\n",
      "Step 479, Minibatch Loss= 0.1498, Training Accuracy= 0.945\n",
      "Step 480, Minibatch Loss= 0.0904, Training Accuracy= 0.977\n",
      "Step 481, Minibatch Loss= 0.1389, Training Accuracy= 0.938\n",
      "Step 482, Minibatch Loss= 0.0760, Training Accuracy= 0.977\n",
      "Step 483, Minibatch Loss= 0.1419, Training Accuracy= 0.945\n",
      "Step 484, Minibatch Loss= 0.1306, Training Accuracy= 0.961\n",
      "Step 485, Minibatch Loss= 0.1623, Training Accuracy= 0.922\n",
      "Step 486, Minibatch Loss= 0.1208, Training Accuracy= 0.977\n",
      "Step 487, Minibatch Loss= 0.0740, Training Accuracy= 0.984\n",
      "Step 488, Minibatch Loss= 0.1291, Training Accuracy= 0.953\n",
      "Step 489, Minibatch Loss= 0.1077, Training Accuracy= 0.953\n",
      "Step 490, Minibatch Loss= 0.2672, Training Accuracy= 0.922\n",
      "Step 491, Minibatch Loss= 0.0955, Training Accuracy= 0.969\n",
      "Step 492, Minibatch Loss= 0.2058, Training Accuracy= 0.930\n",
      "Step 493, Minibatch Loss= 0.1687, Training Accuracy= 0.938\n",
      "Step 494, Minibatch Loss= 0.1259, Training Accuracy= 0.945\n",
      "Step 495, Minibatch Loss= 0.1163, Training Accuracy= 0.961\n",
      "Step 496, Minibatch Loss= 0.1768, Training Accuracy= 0.945\n",
      "Step 497, Minibatch Loss= 0.0998, Training Accuracy= 0.969\n",
      "Step 498, Minibatch Loss= 0.1585, Training Accuracy= 0.930\n",
      "Step 499, Minibatch Loss= 0.1612, Training Accuracy= 0.938\n",
      "Step 500, Minibatch Loss= 0.1616, Training Accuracy= 0.945\n",
      "Step 100, Training Accuracy= 1.0\n",
      "Step 200, Training Accuracy= 1.0\n",
      "Step 300, Training Accuracy= 1.0\n",
      "Step 400, Training Accuracy= 1.0\n",
      "Step 500, Training Accuracy= 1.0\n",
      "Step 600, Training Accuracy= 1.0\n",
      "Step 700, Training Accuracy= 1.0\n",
      "Step 800, Training Accuracy= 1.0\n",
      "Step 900, Training Accuracy= 1.0\n",
      "Step 1000, Training Accuracy= 1.0\n",
      "Step 1100, Training Accuracy= 1.0\n",
      "Step 1200, Training Accuracy= 1.0\n",
      "Step 1300, Training Accuracy= 1.0\n",
      "Step 1400, Training Accuracy= 1.0\n",
      "Step 1500, Training Accuracy= 1.0\n",
      "Step 1600, Training Accuracy= 1.0\n",
      "Step 1700, Training Accuracy= 1.0\n",
      "Step 1800, Training Accuracy= 0.0\n",
      "Step 1900, Training Accuracy= 1.0\n",
      "Step 2000, Training Accuracy= 1.0\n",
      "Step 2100, Training Accuracy= 1.0\n",
      "Step 2200, Training Accuracy= 1.0\n",
      "Step 2300, Training Accuracy= 1.0\n",
      "Step 2400, Training Accuracy= 1.0\n",
      "Step 2500, Training Accuracy= 1.0\n",
      "Step 2600, Training Accuracy= 1.0\n",
      "Step 2700, Training Accuracy= 1.0\n",
      "Step 2800, Training Accuracy= 1.0\n",
      "Step 2900, Training Accuracy= 1.0\n",
      "Step 3000, Training Accuracy= 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3100, Training Accuracy= 1.0\n",
      "Step 3200, Training Accuracy= 1.0\n",
      "Step 3300, Training Accuracy= 1.0\n",
      "Step 3400, Training Accuracy= 1.0\n",
      "Step 3500, Training Accuracy= 1.0\n",
      "Step 3600, Training Accuracy= 1.0\n",
      "Step 3700, Training Accuracy= 1.0\n",
      "Step 3800, Training Accuracy= 1.0\n",
      "Step 3900, Training Accuracy= 1.0\n",
      "Step 4000, Training Accuracy= 1.0\n",
      "Step 4100, Training Accuracy= 1.0\n",
      "Step 4200, Training Accuracy= 1.0\n",
      "Step 4300, Training Accuracy= 0.0\n",
      "Step 4400, Training Accuracy= 1.0\n",
      "Step 4500, Training Accuracy= 1.0\n",
      "Step 4600, Training Accuracy= 1.0\n",
      "Step 4700, Training Accuracy= 1.0\n",
      "Step 4800, Training Accuracy= 1.0\n",
      "Step 4900, Training Accuracy= 1.0\n",
      "Step 5000, Training Accuracy= 1.0\n",
      "Step 5100, Training Accuracy= 1.0\n",
      "Step 5200, Training Accuracy= 1.0\n",
      "Step 5300, Training Accuracy= 1.0\n",
      "Step 5400, Training Accuracy= 1.0\n",
      "Step 5500, Training Accuracy= 1.0\n",
      "Optimization Finished! 0.952821629468336\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node input_producer/input_producer/input_producer_EnqueueMany}}]]\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueRunnerThread-batch_1/fifo_queue-batch_1/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n",
      "\n",
      "Exception in thread QueueRunnerThread-batch_1/fifo_queue-batch_1/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n",
      "Exception in thread QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n",
      "Exception in thread QueueRunnerThread-input_producer/input_producer-input_producer/input_producer/input_producer_EnqueueMany:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node input_producer/input_producer/input_producer_EnqueueMany}}]]\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node input_producer_1/input_producer/input_producer_EnqueueMany}}]]\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueRunnerThread-batch_1/fifo_queue-batch_1/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n",
      "\n",
      "Exception in thread QueueRunnerThread-input_producer_1/input_producer-input_producer_1/input_producer/input_producer_EnqueueMany:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node input_producer_1/input_producer/input_producer_EnqueueMany}}]]\n",
      "\n",
      "Exception in thread QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n",
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n"
     ]
    }
   ],
   "source": [
    "logits_train = conv_net(trainImages, N_CLASSES, dropout, reuse=False, is_training=True)\n",
    "# Create another graph for testing that reuse the same weights\n",
    "logits_test = conv_net(trainImages, N_CLASSES, dropout, reuse=True, is_training=False)\n",
    "\n",
    "\n",
    "logits_test_test = conv_net(testImages, N_CLASSES, dropout, reuse=True, is_training=False)\n",
    "\n",
    "# Define loss and optimizer (with train logits, for dropout to take effect)\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits_train, labels=trainLabels))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.cast(trainLabels, tf.int64))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "correct_pred_test = tf.equal(tf.argmax(logits_test_test, 1), tf.cast(testLabels, tf.int64))\n",
    "accuracy_test = tf.reduce_mean(tf.cast(correct_pred_test, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the data queue\n",
    "    tf.train.start_queue_runners()\n",
    "\n",
    "    # Training cycle\n",
    "    \n",
    "    train_acc = 0;\n",
    "    \n",
    "    for step in range(1, num_steps+1):\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            # Run optimization and calculate batch loss and accuracy\n",
    "            _, loss, acc = sess.run([train_op, loss_op, accuracy])\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "        else:\n",
    "            # Only run the optimization op (backprop)\n",
    "            sess.run(train_op)\n",
    "            train_acc\n",
    "            \n",
    "    test_accuracy = 0;\n",
    "    for step in range(1, testSize + 1):\n",
    "        acc2 = sess.run(accuracy_test)\n",
    "        test_accuracy += acc2\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            # Run optimization and calculate batch loss and accuracy\n",
    "            print(\"Step \" + str(step) + \", Training Accuracy= \" + str(acc2))\n",
    "\n",
    "            \n",
    "    test_accuracy = test_accuracy/testSize\n",
    "    print(\"Optimization Finished! \" + str(test_accuracy))\n",
    "    # Save your model\n",
    "    saver.save(sess, 'my_tf_model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952821629468336"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Exception in QueueRunner: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n",
      "\n",
      "Exception in thread QueueRunnerThread-batch/fifo_queue-batch/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch/fifo_queue_enqueue}}]]\n",
      "\n",
      "Exception in thread QueueRunnerThread-batch_1/fifo_queue-batch_1/fifo_queue_enqueue:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\", line 257, in _run\n",
      "    enqueue_callable()\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1257, in _single_operation_run\n",
      "    self._call_tf_sessionrun(None, {}, [], target_list, None)\n",
      "  File \"/usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node batch_1/fifo_queue_enqueue}}]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LEFT OFF AT PIPE THE DATASET TO A MODEL\n",
    "#NEED TO:\n",
    "#    SEPERATE DATA INTO TRAINING AND TESTING ###DONE\n",
    "#    TRAIN MODEL\n",
    "#    TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
