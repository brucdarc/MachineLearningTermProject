{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = read_images('/s/bach/g/under/cutreap/Desktop/cs445/cell_images/', 'folder', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "# Dataset Parameters - CHANGE HERE\n",
    "MODE = 'folder' # or 'file', if you choose a plain text file (see above).\n",
    "DATASET_PATH = '/path/to/dataset/' # the dataset file or root folder path.\n",
    "\n",
    "# Image Parameters\n",
    "N_CLASSES = 2 # CHANGE HERE, total number of classes\n",
    "IMG_HEIGHT = 128 # CHANGE HERE, the image height to be resized to\n",
    "IMG_WIDTH = 128 # CHANGE HERE, the image width to be resized to\n",
    "CHANNELS = 3 # The 3 color channels, change to 1 if grayscale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-3be6b04b0dbc>:40: slice_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(tuple(tensor_list)).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:374: range_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.range(limit).shuffle(limit).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:320: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-3be6b04b0dbc>:57: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# Build the data input\n",
    "X, Y = read_images('/s/bach/g/under/cutreap/Desktop/cs445/cell_images/', 'folder', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'batch:0' shape=(200, 128, 128, 3) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-fa5d7d692a43>:8: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-fa5d7d692a43>:10: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-fa5d7d692a43>:24: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-fa5d7d692a43>:26: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-5-7369b9677710>:28: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Step 1, Minibatch Loss= 0.7087, Training Accuracy= 0.605\n",
      "Step 2, Minibatch Loss= 1.3875, Training Accuracy= 0.480\n",
      "Step 3, Minibatch Loss= 1.1714, Training Accuracy= 0.555\n",
      "Step 4, Minibatch Loss= 0.7619, Training Accuracy= 0.540\n",
      "Step 5, Minibatch Loss= 0.8099, Training Accuracy= 0.515\n",
      "Step 6, Minibatch Loss= 0.8986, Training Accuracy= 0.455\n",
      "Step 7, Minibatch Loss= 0.6261, Training Accuracy= 0.740\n",
      "Step 8, Minibatch Loss= 0.6392, Training Accuracy= 0.620\n",
      "Step 9, Minibatch Loss= 0.6741, Training Accuracy= 0.605\n",
      "Step 10, Minibatch Loss= 0.5921, Training Accuracy= 0.710\n",
      "Step 11, Minibatch Loss= 0.5942, Training Accuracy= 0.725\n",
      "Step 12, Minibatch Loss= 0.6341, Training Accuracy= 0.625\n",
      "Step 13, Minibatch Loss= 0.5990, Training Accuracy= 0.655\n",
      "Step 14, Minibatch Loss= 0.5663, Training Accuracy= 0.770\n",
      "Step 15, Minibatch Loss= 0.5540, Training Accuracy= 0.760\n",
      "Step 16, Minibatch Loss= 0.5239, Training Accuracy= 0.765\n",
      "Step 17, Minibatch Loss= 0.5207, Training Accuracy= 0.740\n",
      "Step 18, Minibatch Loss= 0.4719, Training Accuracy= 0.805\n",
      "Step 19, Minibatch Loss= 0.4890, Training Accuracy= 0.770\n",
      "Step 20, Minibatch Loss= 0.4996, Training Accuracy= 0.780\n",
      "Step 21, Minibatch Loss= 0.4718, Training Accuracy= 0.795\n",
      "Step 22, Minibatch Loss= 0.5407, Training Accuracy= 0.770\n",
      "Step 23, Minibatch Loss= 0.4808, Training Accuracy= 0.795\n",
      "Step 24, Minibatch Loss= 0.4662, Training Accuracy= 0.785\n",
      "Step 25, Minibatch Loss= 0.4901, Training Accuracy= 0.760\n",
      "Step 26, Minibatch Loss= 0.4669, Training Accuracy= 0.780\n",
      "Step 27, Minibatch Loss= 0.4366, Training Accuracy= 0.865\n",
      "Step 28, Minibatch Loss= 0.4407, Training Accuracy= 0.790\n",
      "Step 29, Minibatch Loss= 0.5434, Training Accuracy= 0.710\n",
      "Step 30, Minibatch Loss= 0.4075, Training Accuracy= 0.800\n",
      "Step 31, Minibatch Loss= 0.4329, Training Accuracy= 0.840\n",
      "Step 32, Minibatch Loss= 0.3402, Training Accuracy= 0.875\n",
      "Step 33, Minibatch Loss= 0.4035, Training Accuracy= 0.830\n",
      "Step 34, Minibatch Loss= 0.3482, Training Accuracy= 0.825\n",
      "Step 35, Minibatch Loss= 0.3652, Training Accuracy= 0.845\n",
      "Step 36, Minibatch Loss= 0.3486, Training Accuracy= 0.850\n",
      "Step 37, Minibatch Loss= 0.4180, Training Accuracy= 0.825\n",
      "Step 38, Minibatch Loss= 0.3527, Training Accuracy= 0.825\n",
      "Step 39, Minibatch Loss= 0.2996, Training Accuracy= 0.875\n",
      "Step 40, Minibatch Loss= 0.3835, Training Accuracy= 0.825\n",
      "Step 41, Minibatch Loss= 0.3797, Training Accuracy= 0.845\n",
      "Step 42, Minibatch Loss= 0.3439, Training Accuracy= 0.845\n",
      "Step 43, Minibatch Loss= 0.4010, Training Accuracy= 0.865\n",
      "Step 44, Minibatch Loss= 0.3237, Training Accuracy= 0.860\n",
      "Step 45, Minibatch Loss= 0.3755, Training Accuracy= 0.865\n",
      "Step 46, Minibatch Loss= 0.2406, Training Accuracy= 0.905\n",
      "Step 47, Minibatch Loss= 0.2850, Training Accuracy= 0.880\n",
      "Step 48, Minibatch Loss= 0.2609, Training Accuracy= 0.920\n",
      "Step 49, Minibatch Loss= 0.3892, Training Accuracy= 0.825\n",
      "Step 50, Minibatch Loss= 0.2303, Training Accuracy= 0.895\n",
      "Step 51, Minibatch Loss= 0.2474, Training Accuracy= 0.890\n",
      "Step 52, Minibatch Loss= 0.2708, Training Accuracy= 0.890\n",
      "Step 53, Minibatch Loss= 0.2516, Training Accuracy= 0.905\n",
      "Step 54, Minibatch Loss= 0.1781, Training Accuracy= 0.930\n",
      "Step 55, Minibatch Loss= 0.2682, Training Accuracy= 0.905\n",
      "Step 56, Minibatch Loss= 0.3154, Training Accuracy= 0.870\n",
      "Step 57, Minibatch Loss= 0.3054, Training Accuracy= 0.905\n",
      "Step 58, Minibatch Loss= 0.2333, Training Accuracy= 0.945\n",
      "Step 59, Minibatch Loss= 0.3237, Training Accuracy= 0.915\n",
      "Step 60, Minibatch Loss= 0.2646, Training Accuracy= 0.905\n",
      "Step 61, Minibatch Loss= 0.2423, Training Accuracy= 0.895\n",
      "Step 62, Minibatch Loss= 0.2980, Training Accuracy= 0.880\n",
      "Step 63, Minibatch Loss= 0.2308, Training Accuracy= 0.905\n",
      "Step 64, Minibatch Loss= 0.1595, Training Accuracy= 0.945\n",
      "Step 65, Minibatch Loss= 0.2729, Training Accuracy= 0.895\n",
      "Step 66, Minibatch Loss= 0.2402, Training Accuracy= 0.945\n",
      "Step 67, Minibatch Loss= 0.2940, Training Accuracy= 0.905\n",
      "Step 68, Minibatch Loss= 0.2751, Training Accuracy= 0.875\n",
      "Step 69, Minibatch Loss= 0.2320, Training Accuracy= 0.920\n",
      "Step 70, Minibatch Loss= 0.2442, Training Accuracy= 0.920\n",
      "Step 71, Minibatch Loss= 0.3426, Training Accuracy= 0.905\n",
      "Step 72, Minibatch Loss= 0.2805, Training Accuracy= 0.910\n",
      "Step 73, Minibatch Loss= 0.1869, Training Accuracy= 0.940\n",
      "Step 74, Minibatch Loss= 0.2162, Training Accuracy= 0.945\n",
      "Step 75, Minibatch Loss= 0.2009, Training Accuracy= 0.925\n",
      "Step 76, Minibatch Loss= 0.1639, Training Accuracy= 0.945\n",
      "Step 77, Minibatch Loss= 0.2686, Training Accuracy= 0.895\n",
      "Step 78, Minibatch Loss= 0.2839, Training Accuracy= 0.875\n",
      "Step 79, Minibatch Loss= 0.1958, Training Accuracy= 0.915\n",
      "Step 80, Minibatch Loss= 0.2074, Training Accuracy= 0.960\n",
      "Step 81, Minibatch Loss= 0.1633, Training Accuracy= 0.955\n",
      "Step 82, Minibatch Loss= 0.1908, Training Accuracy= 0.940\n",
      "Step 83, Minibatch Loss= 0.2342, Training Accuracy= 0.945\n",
      "Step 84, Minibatch Loss= 0.2067, Training Accuracy= 0.930\n",
      "Step 85, Minibatch Loss= 0.2066, Training Accuracy= 0.925\n",
      "Step 86, Minibatch Loss= 0.1979, Training Accuracy= 0.930\n",
      "Step 87, Minibatch Loss= 0.2672, Training Accuracy= 0.915\n",
      "Step 88, Minibatch Loss= 0.2037, Training Accuracy= 0.930\n",
      "Step 89, Minibatch Loss= 0.1893, Training Accuracy= 0.930\n",
      "Step 90, Minibatch Loss= 0.1663, Training Accuracy= 0.950\n",
      "Step 91, Minibatch Loss= 0.1543, Training Accuracy= 0.955\n",
      "Step 92, Minibatch Loss= 0.2162, Training Accuracy= 0.905\n",
      "Step 93, Minibatch Loss= 0.2083, Training Accuracy= 0.935\n",
      "Step 94, Minibatch Loss= 0.2353, Training Accuracy= 0.935\n",
      "Step 95, Minibatch Loss= 0.1707, Training Accuracy= 0.940\n",
      "Step 96, Minibatch Loss= 0.1900, Training Accuracy= 0.935\n",
      "Step 97, Minibatch Loss= 0.2340, Training Accuracy= 0.910\n",
      "Step 98, Minibatch Loss= 0.2382, Training Accuracy= 0.915\n",
      "Step 99, Minibatch Loss= 0.1554, Training Accuracy= 0.950\n",
      "Step 100, Minibatch Loss= 0.3033, Training Accuracy= 0.920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 101, Minibatch Loss= 0.1515, Training Accuracy= 0.960\n",
      "Step 102, Minibatch Loss= 0.1846, Training Accuracy= 0.945\n",
      "Step 103, Minibatch Loss= 0.2571, Training Accuracy= 0.915\n",
      "Step 104, Minibatch Loss= 0.2687, Training Accuracy= 0.910\n",
      "Step 105, Minibatch Loss= 0.2228, Training Accuracy= 0.920\n",
      "Step 106, Minibatch Loss= 0.2305, Training Accuracy= 0.915\n",
      "Step 107, Minibatch Loss= 0.2182, Training Accuracy= 0.950\n",
      "Step 108, Minibatch Loss= 0.2274, Training Accuracy= 0.940\n",
      "Step 109, Minibatch Loss= 0.1049, Training Accuracy= 0.975\n",
      "Step 110, Minibatch Loss= 0.2045, Training Accuracy= 0.920\n",
      "Step 111, Minibatch Loss= 0.2108, Training Accuracy= 0.905\n",
      "Step 112, Minibatch Loss= 0.1636, Training Accuracy= 0.950\n",
      "Step 113, Minibatch Loss= 0.2266, Training Accuracy= 0.915\n",
      "Step 114, Minibatch Loss= 0.1231, Training Accuracy= 0.950\n",
      "Step 115, Minibatch Loss= 0.2029, Training Accuracy= 0.935\n",
      "Step 116, Minibatch Loss= 0.1549, Training Accuracy= 0.950\n",
      "Step 117, Minibatch Loss= 0.3691, Training Accuracy= 0.905\n",
      "Step 118, Minibatch Loss= 0.1714, Training Accuracy= 0.940\n",
      "Step 119, Minibatch Loss= 0.2116, Training Accuracy= 0.925\n",
      "Step 120, Minibatch Loss= 0.2254, Training Accuracy= 0.920\n",
      "Step 121, Minibatch Loss= 0.2812, Training Accuracy= 0.900\n",
      "Step 122, Minibatch Loss= 0.2061, Training Accuracy= 0.930\n",
      "Step 123, Minibatch Loss= 0.1866, Training Accuracy= 0.930\n",
      "Step 124, Minibatch Loss= 0.2094, Training Accuracy= 0.905\n",
      "Step 125, Minibatch Loss= 0.2772, Training Accuracy= 0.925\n",
      "Step 126, Minibatch Loss= 0.1572, Training Accuracy= 0.955\n",
      "Step 127, Minibatch Loss= 0.1654, Training Accuracy= 0.935\n",
      "Step 128, Minibatch Loss= 0.1879, Training Accuracy= 0.900\n",
      "Step 129, Minibatch Loss= 0.2010, Training Accuracy= 0.925\n",
      "Step 130, Minibatch Loss= 0.1620, Training Accuracy= 0.930\n",
      "Step 131, Minibatch Loss= 0.2005, Training Accuracy= 0.905\n",
      "Step 132, Minibatch Loss= 0.1935, Training Accuracy= 0.930\n",
      "Step 133, Minibatch Loss= 0.1657, Training Accuracy= 0.925\n",
      "Step 134, Minibatch Loss= 0.2260, Training Accuracy= 0.940\n",
      "Step 135, Minibatch Loss= 0.2744, Training Accuracy= 0.950\n",
      "Step 136, Minibatch Loss= 0.1757, Training Accuracy= 0.945\n",
      "Step 137, Minibatch Loss= 0.2098, Training Accuracy= 0.935\n",
      "Step 138, Minibatch Loss= 0.1944, Training Accuracy= 0.930\n",
      "Step 139, Minibatch Loss= 0.1547, Training Accuracy= 0.950\n",
      "Step 140, Minibatch Loss= 0.1453, Training Accuracy= 0.965\n",
      "Step 141, Minibatch Loss= 0.1290, Training Accuracy= 0.965\n",
      "Step 142, Minibatch Loss= 0.2680, Training Accuracy= 0.915\n",
      "Step 143, Minibatch Loss= 0.1949, Training Accuracy= 0.950\n",
      "Step 144, Minibatch Loss= 0.1006, Training Accuracy= 0.965\n",
      "Step 145, Minibatch Loss= 0.1359, Training Accuracy= 0.965\n",
      "Step 146, Minibatch Loss= 0.1773, Training Accuracy= 0.945\n",
      "Step 147, Minibatch Loss= 0.1345, Training Accuracy= 0.945\n",
      "Step 148, Minibatch Loss= 0.1968, Training Accuracy= 0.935\n",
      "Step 149, Minibatch Loss= 0.1919, Training Accuracy= 0.940\n",
      "Step 150, Minibatch Loss= 0.1615, Training Accuracy= 0.955\n",
      "Step 151, Minibatch Loss= 0.1188, Training Accuracy= 0.940\n",
      "Step 152, Minibatch Loss= 0.0698, Training Accuracy= 0.980\n",
      "Step 153, Minibatch Loss= 0.1124, Training Accuracy= 0.960\n",
      "Step 154, Minibatch Loss= 0.1658, Training Accuracy= 0.935\n",
      "Step 155, Minibatch Loss= 0.0991, Training Accuracy= 0.975\n",
      "Step 156, Minibatch Loss= 0.2198, Training Accuracy= 0.930\n",
      "Step 157, Minibatch Loss= 0.2233, Training Accuracy= 0.915\n",
      "Step 158, Minibatch Loss= 0.0890, Training Accuracy= 0.970\n",
      "Step 159, Minibatch Loss= 0.1725, Training Accuracy= 0.960\n",
      "Step 160, Minibatch Loss= 0.1837, Training Accuracy= 0.930\n",
      "Step 161, Minibatch Loss= 0.0874, Training Accuracy= 0.965\n",
      "Step 162, Minibatch Loss= 0.1276, Training Accuracy= 0.965\n",
      "Step 163, Minibatch Loss= 0.1101, Training Accuracy= 0.965\n",
      "Step 164, Minibatch Loss= 0.0893, Training Accuracy= 0.965\n",
      "Step 165, Minibatch Loss= 0.2013, Training Accuracy= 0.940\n",
      "Step 166, Minibatch Loss= 0.1817, Training Accuracy= 0.925\n",
      "Step 167, Minibatch Loss= 0.1467, Training Accuracy= 0.935\n",
      "Step 168, Minibatch Loss= 0.1532, Training Accuracy= 0.965\n",
      "Step 169, Minibatch Loss= 0.1750, Training Accuracy= 0.925\n",
      "Step 170, Minibatch Loss= 0.1612, Training Accuracy= 0.945\n",
      "Step 171, Minibatch Loss= 0.2029, Training Accuracy= 0.930\n",
      "Step 172, Minibatch Loss= 0.2465, Training Accuracy= 0.910\n",
      "Step 173, Minibatch Loss= 0.2504, Training Accuracy= 0.905\n",
      "Step 174, Minibatch Loss= 0.1419, Training Accuracy= 0.960\n",
      "Step 175, Minibatch Loss= 0.2164, Training Accuracy= 0.915\n",
      "Step 176, Minibatch Loss= 0.2557, Training Accuracy= 0.930\n",
      "Step 177, Minibatch Loss= 0.2612, Training Accuracy= 0.930\n",
      "Step 178, Minibatch Loss= 0.1425, Training Accuracy= 0.945\n",
      "Step 179, Minibatch Loss= 0.1281, Training Accuracy= 0.965\n",
      "Step 180, Minibatch Loss= 0.1229, Training Accuracy= 0.965\n",
      "Step 181, Minibatch Loss= 0.2126, Training Accuracy= 0.950\n",
      "Step 182, Minibatch Loss= 0.1682, Training Accuracy= 0.955\n",
      "Step 183, Minibatch Loss= 0.1618, Training Accuracy= 0.945\n",
      "Step 184, Minibatch Loss= 0.2116, Training Accuracy= 0.935\n",
      "Step 185, Minibatch Loss= 0.2020, Training Accuracy= 0.950\n",
      "Step 186, Minibatch Loss= 0.1623, Training Accuracy= 0.935\n",
      "Step 187, Minibatch Loss= 0.0940, Training Accuracy= 0.970\n",
      "Step 188, Minibatch Loss= 0.1276, Training Accuracy= 0.950\n",
      "Step 189, Minibatch Loss= 0.1920, Training Accuracy= 0.940\n",
      "Step 190, Minibatch Loss= 0.1868, Training Accuracy= 0.935\n",
      "Step 191, Minibatch Loss= 0.1189, Training Accuracy= 0.965\n",
      "Step 192, Minibatch Loss= 0.1713, Training Accuracy= 0.930\n",
      "Step 193, Minibatch Loss= 0.0925, Training Accuracy= 0.975\n",
      "Step 194, Minibatch Loss= 0.2114, Training Accuracy= 0.935\n",
      "Step 195, Minibatch Loss= 0.2206, Training Accuracy= 0.940\n",
      "Step 196, Minibatch Loss= 0.1868, Training Accuracy= 0.945\n",
      "Step 197, Minibatch Loss= 0.1632, Training Accuracy= 0.935\n",
      "Step 198, Minibatch Loss= 0.1394, Training Accuracy= 0.960\n",
      "Step 199, Minibatch Loss= 0.1081, Training Accuracy= 0.960\n",
      "Step 200, Minibatch Loss= 0.1132, Training Accuracy= 0.965\n",
      "Step 201, Minibatch Loss= 0.1147, Training Accuracy= 0.960\n",
      "Step 202, Minibatch Loss= 0.0692, Training Accuracy= 0.985\n",
      "Step 203, Minibatch Loss= 0.0881, Training Accuracy= 0.970\n",
      "Step 204, Minibatch Loss= 0.1519, Training Accuracy= 0.950\n",
      "Step 205, Minibatch Loss= 0.1931, Training Accuracy= 0.910\n",
      "Step 206, Minibatch Loss= 0.1420, Training Accuracy= 0.950\n",
      "Step 207, Minibatch Loss= 0.1865, Training Accuracy= 0.925\n",
      "Step 208, Minibatch Loss= 0.0804, Training Accuracy= 0.980\n",
      "Step 209, Minibatch Loss= 0.2392, Training Accuracy= 0.950\n",
      "Step 210, Minibatch Loss= 0.1799, Training Accuracy= 0.925\n",
      "Step 211, Minibatch Loss= 0.1198, Training Accuracy= 0.955\n",
      "Step 212, Minibatch Loss= 0.1463, Training Accuracy= 0.950\n",
      "Step 213, Minibatch Loss= 0.1693, Training Accuracy= 0.945\n",
      "Step 214, Minibatch Loss= 0.0523, Training Accuracy= 0.985\n",
      "Step 215, Minibatch Loss= 0.3000, Training Accuracy= 0.915\n",
      "Step 216, Minibatch Loss= 0.1567, Training Accuracy= 0.965\n",
      "Step 217, Minibatch Loss= 0.2507, Training Accuracy= 0.940\n",
      "Step 218, Minibatch Loss= 0.1838, Training Accuracy= 0.940\n",
      "Step 219, Minibatch Loss= 0.2158, Training Accuracy= 0.940\n",
      "Step 220, Minibatch Loss= 0.1734, Training Accuracy= 0.935\n",
      "Step 221, Minibatch Loss= 0.1423, Training Accuracy= 0.950\n",
      "Step 222, Minibatch Loss= 0.1313, Training Accuracy= 0.970\n",
      "Step 223, Minibatch Loss= 0.2394, Training Accuracy= 0.925\n",
      "Step 224, Minibatch Loss= 0.2474, Training Accuracy= 0.950\n",
      "Step 225, Minibatch Loss= 0.1506, Training Accuracy= 0.960\n",
      "Step 226, Minibatch Loss= 0.0950, Training Accuracy= 0.970\n",
      "Step 227, Minibatch Loss= 0.1203, Training Accuracy= 0.975\n",
      "Step 228, Minibatch Loss= 0.1272, Training Accuracy= 0.960\n",
      "Step 229, Minibatch Loss= 0.2207, Training Accuracy= 0.940\n",
      "Step 230, Minibatch Loss= 0.1701, Training Accuracy= 0.935\n",
      "Step 231, Minibatch Loss= 0.0937, Training Accuracy= 0.960\n",
      "Step 232, Minibatch Loss= 0.1185, Training Accuracy= 0.955\n"
     ]
    }
   ],
   "source": [
    "logits_train = conv_net(X, N_CLASSES, dropout, reuse=False, is_training=True)\n",
    "# Create another graph for testing that reuse the same weights\n",
    "logits_test = conv_net(X, N_CLASSES, dropout, reuse=True, is_training=False)\n",
    "\n",
    "# Define loss and optimizer (with train logits, for dropout to take effect)\n",
    "loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits_train, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.cast(Y, tf.int64))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Start the data queue\n",
    "    tf.train.start_queue_runners()\n",
    "\n",
    "    # Training cycle\n",
    "    for step in range(1, num_steps+1):\n",
    "\n",
    "        if step % display_step == 0:\n",
    "            # Run optimization and calculate batch loss and accuracy\n",
    "            _, loss, acc = sess.run([train_op, loss_op, accuracy])\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "        else:\n",
    "            # Only run the optimization op (backprop)\n",
    "            sess.run(train_op)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    # Save your model\n",
    "    saver.save(sess, 'my_tf_model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create model\n",
    "def conv_net(x, n_classes, dropout, reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 64, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 5, 3)\n",
    "\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2 \n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 5, 3)\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(conv2, 128, 3)\n",
    "        conv3 = tf.layers.max_pooling2d(conv3, 3, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv3)\n",
    "\n",
    "        # Fully connected layer (in contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        #fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "        # Because 'softmax_cross_entropy_with_logits' already apply softmax,\n",
    "        # we only apply softmax to testing network\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images(dataset_path, mode, batch_size):\n",
    "    imagepaths, labels = list(), list()\n",
    "    if mode == 'file':\n",
    "        # Read dataset file\n",
    "        with open(dataset_path) as f:\n",
    "            data = f.read().splitlines()\n",
    "        for d in data:\n",
    "            imagepaths.append(d.split(' ')[0])\n",
    "            labels.append(int(d.split(' ')[1]))\n",
    "    elif mode == 'folder':\n",
    "        # An ID will be affected to each sub-folders by alphabetical order\n",
    "        label = 0\n",
    "        # List the directory\n",
    "        try:  # Python 2\n",
    "            classes = sorted(os.walk(dataset_path).next()[1])\n",
    "        except Exception:  # Python 3\n",
    "            classes = sorted(os.walk(dataset_path).__next__()[1])\n",
    "        # List each sub-directory (the classes)\n",
    "        for c in classes:\n",
    "            c_dir = os.path.join(dataset_path, c)\n",
    "            try:  # Python 2\n",
    "                walk = os.walk(c_dir).next()\n",
    "            except Exception:  # Python 3\n",
    "                walk = os.walk(c_dir).__next__()\n",
    "            # Add each image to the training set\n",
    "            for sample in walk[2]:\n",
    "                # Only keeps jpeg images\n",
    "                if sample.endswith('.png') or sample.endswith('.jpeg'):\n",
    "                    imagepaths.append(os.path.join(c_dir, sample))\n",
    "                    labels.append(label)\n",
    "            label += 1\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode.\")\n",
    "\n",
    "    # Convert to Tensor\n",
    "    imagepaths = tf.convert_to_tensor(imagepaths, dtype=tf.string)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "    # Build a TF Queue, shuffle data\n",
    "    image, label = tf.train.slice_input_producer([imagepaths, labels],\n",
    "                                                 shuffle=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Read images from disk\n",
    "    image = tf.read_file(image)\n",
    "    image = tf.image.decode_png(image, channels=CHANNELS)\n",
    "\n",
    "    # Resize images to a common size\n",
    "    image = tf.image.resize_images(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "\n",
    "    # Normalize\n",
    "    image = image * 1.0/127.5 - 1.0\n",
    "\n",
    "    # Create batches\n",
    "    X, Y = tf.train.batch([image, label], batch_size=batch_size,\n",
    "                          capacity=batch_size * 8,\n",
    "                          num_threads=4)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = Image.open('/s/bach/g/under/cutreap/Desktop/cs445/cell_images/Parasitized/C33P1thinF_IMG_20150619_115740a_cell_161.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 127, 124])\n"
     ]
    }
   ],
   "source": [
    "x = TF.to_tensor(image)\n",
    "x.unsqueeze_(0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/anaconda3-4.4.0/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 33s 546us/sample - loss: 0.0181 - acc: 0.9944\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 35s 576us/sample - loss: 0.0132 - acc: 0.9958\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 33s 544us/sample - loss: 0.0117 - acc: 0.9961\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 29s 489us/sample - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 28s 474us/sample - loss: 0.0097 - acc: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f58a7f78320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 159us/sample - loss: 0.0387 - acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9912\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
